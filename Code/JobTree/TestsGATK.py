# John Vivian
# 4-14-15

"""
Unit tests for functions within the
"""

import unittest
from jobtree_gatk_pipeline import *


class TestSupportGATK(unittest.TestCase):
    @classmethod
    def setUpClass(self):
        self.inputs = {'test.vcf': 'www.google.com/index.html',
                       'normal.bam': 'www.google.com/index.html'}
        self.UUID = uuid.uuid4()
        self.local_dir = 'test_out/'
        self.shared_dir = os.path.join(self.local_dir, '{}/'.format(self.UUID))
        self.pair_dir = os.path.join(self.shared_dir, 'pair')

        # Create Object for testing
        self.gatk = SupportGATK(self.inputs, self.local_dir, self.shared_dir, self.pair_dir)

    def test_GetInputPath(self):
        test_path = self.gatk.get_input_path('test.vcf')
        normal_path = self.gatk.get_input_path('normal.bam')

        self.assertEqual(test_path, os.path.join(self.shared_dir, 'test.vcf'))
        self.assertEqual(normal_path, os.path.join(self.pair_dir, 'normal.bam'))

    def test_UploadToS3(self):

        # Using files generated by "GetInputPath"
        file1 = 'test_out/{}/test.vcf'.format(self.UUID)
        file2 = 'test_out/{}/pair/normal.bam'.format(self.UUID)

        self.gatk.upload_to_S3(file1)
        self.gatk.upload_to_S3(file2)

        try:
            conn = boto.connect_s3()
            bucket = conn.get_bucket('bd2k-jobtree_gatk_pipeline')
            keys = bucket.get_all_keys()
        except:
            raise RuntimeError('Connection to S3 failed')

        self.assertTrue('{}/test.vcf'.format(self.UUID) in [x.name for x in keys])
        self.assertTrue('{}/pair/normal.bam'.format(self.UUID) in [x.name for x in keys])

    def test_GetIntermediatePath(self):

        # Download temp files
        file1 = os.path.join(self.shared_dir, 'test.fai')
        file2 = os.path.join(self.pair_dir, 'test.intervals')

        subprocess.check_call(['curl', '-fs', 'www.google.com', '-o', file1])
        subprocess.check_call(['curl', '-fs', 'www.google.com', '-o', file2])

        # Run test_UploadToS3 first to make sure this works -- Upload to S3
        self.gatk.upload_to_S3(file1)
        self.gatk.upload_to_S3(file2)

        # Remove files from local path -- we want GetIntermediatePath to fetch them from S3
        subprocess.check_call(['rm', file1])
        subprocess.check_call(['rm', file2])

        # Retrieve file path (forcing retrieval from S3)
        fai_path = self.gatk.get_intermediate_path('test.fai')
        intervals_path = self.gatk.get_intermediate_path('test.intervals')

        self.assertEqual(fai_path, file1)
        self.assertEqual(intervals_path, file2)

    @classmethod
    def tearDownClass(self):
        # Check with Hannes about 'proper' way to do this
        subprocess.check_call(['rm', '-r', 'test_out/{}/'.format(self.UUID)])

        # Delete generated S3 keys
        conn = boto.connect_s3()
        bucket = conn.get_bucket('bd2k-jobtree_gatk_pipeline')
        keys = bucket.get_all_keys()
        bucket.delete_keys(keys)


def main():
    unittest.main()

if __name__ == '__main__':
    main()